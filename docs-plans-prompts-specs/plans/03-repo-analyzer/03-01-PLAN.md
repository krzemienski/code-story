---
phase: 03-repo-analyzer
type: execute
domain: claude-agent-sdk
---

# Phase 3 Plan 01: Repo Analyzer Agent Core Setup

## Objective

Create the Repo Analyzer Agent using Claude Agent SDK patterns with AgentDefinition and @tool decorators.

**Purpose**: The Repo Analyzer fetches and analyzes repository code to extract structure, patterns, and key components.
**Output**: Working Repo Analyzer Agent with MCP server, tools, and AgentDefinition configuration.

## Context

- @BRIEF.md
- @ROADMAP.md
- @plans/02-intent-agent/02-04-SUMMARY.md

## Claude Agent SDK Pattern

The Repo Analyzer uses the SDK pattern:
1. Define tools with `@tool` decorator
2. Create MCP server with `create_sdk_mcp_server`
3. Configure agent with `AgentDefinition`
4. Use `opus` model for complex code analysis (deep reasoning)

## Tasks

### Task 1: Create GitHub Fetch Tools

**File**: `src/codestory/agents/analyzer/tools/github.py`

```python
"""GitHub repository fetching tools using Claude Agent SDK @tool decorator."""

import httpx
from claude_agent_sdk import tool


GITHUB_API_BASE = "https://api.github.com"


@tool(
    name="fetch_repository_tree",
    description="Fetch the file tree structure of a GitHub repository",
    input_schema={
        "type": "object",
        "properties": {
            "owner": {"type": "string", "description": "Repository owner"},
            "repo": {"type": "string", "description": "Repository name"},
            "branch": {"type": "string", "default": "main", "description": "Branch name"},
            "path": {"type": "string", "default": "", "description": "Path within repo"}
        },
        "required": ["owner", "repo"]
    }
)
async def fetch_repository_tree(args: dict) -> dict:
    """Fetch the file tree from GitHub API."""
    owner = args["owner"]
    repo = args["repo"]
    branch = args.get("branch", "main")
    
    async with httpx.AsyncClient() as client:
        # Get the tree SHA
        ref_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/git/ref/heads/{branch}"
        ref_resp = await client.get(ref_url)
        
        if ref_resp.status_code != 200:
            return {"content": [{"type": "text", "text": f"Error: Could not fetch ref - {ref_resp.text}"}]}
        
        commit_sha = ref_resp.json()["object"]["sha"]
        
        # Get the tree
        tree_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/git/trees/{commit_sha}?recursive=1"
        tree_resp = await client.get(tree_url)
        
        if tree_resp.status_code != 200:
            return {"content": [{"type": "text", "text": f"Error: Could not fetch tree - {tree_resp.text}"}]}
        
        tree_data = tree_resp.json()
        files = [
            {"path": item["path"], "type": item["type"], "size": item.get("size", 0)}
            for item in tree_data.get("tree", [])
        ]
        
        result = {
            "owner": owner,
            "repo": repo,
            "branch": branch,
            "total_files": len([f for f in files if f["type"] == "blob"]),
            "total_directories": len([f for f in files if f["type"] == "tree"]),
            "files": files[:500],  # Limit to 500 entries
            "truncated": tree_data.get("truncated", False),
        }
        
        return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="fetch_file_content",
    description="Fetch the content of a specific file from GitHub",
    input_schema={
        "type": "object",
        "properties": {
            "owner": {"type": "string", "description": "Repository owner"},
            "repo": {"type": "string", "description": "Repository name"},
            "path": {"type": "string", "description": "File path in repository"},
            "branch": {"type": "string", "default": "main", "description": "Branch name"}
        },
        "required": ["owner", "repo", "path"]
    }
)
async def fetch_file_content(args: dict) -> dict:
    """Fetch file content from GitHub API."""
    owner = args["owner"]
    repo = args["repo"]
    path = args["path"]
    branch = args.get("branch", "main")
    
    async with httpx.AsyncClient() as client:
        url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/contents/{path}?ref={branch}"
        resp = await client.get(url)
        
        if resp.status_code != 200:
            return {"content": [{"type": "text", "text": f"Error: Could not fetch file - {resp.text}"}]}
        
        data = resp.json()
        
        if data.get("encoding") == "base64":
            import base64
            content = base64.b64decode(data["content"]).decode("utf-8", errors="replace")
        else:
            content = data.get("content", "")
        
        # Truncate very large files
        if len(content) > 50000:
            content = content[:50000] + "\n... (truncated)"
        
        result = {
            "path": path,
            "size": data.get("size", len(content)),
            "content": content,
            "sha": data.get("sha", ""),
        }
        
        return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="fetch_repository_metadata",
    description="Fetch repository metadata including description, languages, and stats",
    input_schema={
        "type": "object",
        "properties": {
            "owner": {"type": "string", "description": "Repository owner"},
            "repo": {"type": "string", "description": "Repository name"}
        },
        "required": ["owner", "repo"]
    }
)
async def fetch_repository_metadata(args: dict) -> dict:
    """Fetch repository metadata from GitHub API."""
    owner = args["owner"]
    repo = args["repo"]
    
    async with httpx.AsyncClient() as client:
        # Get repo info
        repo_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}"
        repo_resp = await client.get(repo_url)
        
        if repo_resp.status_code != 200:
            return {"content": [{"type": "text", "text": f"Error: Could not fetch repo - {repo_resp.text}"}]}
        
        repo_data = repo_resp.json()
        
        # Get languages
        lang_url = f"{GITHUB_API_BASE}/repos/{owner}/{repo}/languages"
        lang_resp = await client.get(lang_url)
        languages = lang_resp.json() if lang_resp.status_code == 200 else {}
        
        result = {
            "name": repo_data.get("name"),
            "full_name": repo_data.get("full_name"),
            "description": repo_data.get("description"),
            "default_branch": repo_data.get("default_branch", "main"),
            "languages": languages,
            "primary_language": repo_data.get("language"),
            "stars": repo_data.get("stargazers_count", 0),
            "forks": repo_data.get("forks_count", 0),
            "size_kb": repo_data.get("size", 0),
            "created_at": repo_data.get("created_at"),
            "updated_at": repo_data.get("updated_at"),
            "topics": repo_data.get("topics", []),
            "license": repo_data.get("license", {}).get("name") if repo_data.get("license") else None,
        }
        
        return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="parse_github_url",
    description="Parse a GitHub URL to extract owner and repo name",
    input_schema={
        "type": "object",
        "properties": {
            "url": {"type": "string", "description": "GitHub repository URL"}
        },
        "required": ["url"]
    }
)
async def parse_github_url(args: dict) -> dict:
    """Parse GitHub URL to extract owner and repo."""
    url = args["url"].rstrip("/")
    
    # Handle various GitHub URL formats
    if "github.com" not in url:
        return {"content": [{"type": "text", "text": "Error: Not a GitHub URL"}]}
    
    # Remove protocol and github.com
    path = url.split("github.com/")[-1]
    
    # Remove .git suffix if present
    if path.endswith(".git"):
        path = path[:-4]
    
    # Split into owner/repo
    parts = path.split("/")
    if len(parts) < 2:
        return {"content": [{"type": "text", "text": "Error: Invalid GitHub URL format"}]}
    
    result = {
        "owner": parts[0],
        "repo": parts[1],
        "url": f"https://github.com/{parts[0]}/{parts[1]}",
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}
```

### Task 2: Create Analysis Tools

**File**: `src/codestory/agents/analyzer/tools/analysis.py`

```python
"""Code analysis tools using Claude Agent SDK @tool decorator."""

import re
from claude_agent_sdk import tool


# File type categories
FILE_CATEGORIES = {
    "python": [".py"],
    "javascript": [".js", ".jsx", ".mjs"],
    "typescript": [".ts", ".tsx"],
    "config": [".json", ".yaml", ".yml", ".toml", ".ini", ".env"],
    "documentation": [".md", ".rst", ".txt"],
}

# Architectural pattern indicators
ARCHITECTURAL_PATTERNS = {
    "mvc": {"dirs": ["models", "views", "controllers"], "files": ["model.py", "view.py"]},
    "layered": {"dirs": ["presentation", "business", "data", "domain"]},
    "hexagonal": {"dirs": ["adapters", "ports", "domain", "application"]},
    "microservices": {"dirs": ["services"], "files": ["docker-compose.yml"]},
}

# Design pattern signatures
DESIGN_PATTERNS = {
    "singleton": ["_instance", "__new__", "getInstance"],
    "factory": ["create_", "make_", "Factory"],
    "repository": ["Repository", "find", "save", "delete"],
    "observer": ["subscribe", "notify", "Observer", "Listener"],
}


@tool(
    name="categorize_files",
    description="Categorize repository files by type (source, test, config, docs)",
    input_schema={
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {"type": "object"},
                "description": "List of file objects with path and type"
            }
        },
        "required": ["files"]
    }
)
async def categorize_files(args: dict) -> dict:
    """Categorize files by type."""
    files = args["files"]
    
    categories = {
        "source": [],
        "test": [],
        "config": [],
        "documentation": [],
        "other": [],
    }
    
    for f in files:
        if f.get("type") != "blob":
            continue
        
        path = f.get("path", "").lower()
        
        # Test files
        if "test" in path or "spec" in path or "__tests__" in path:
            categories["test"].append(f["path"])
        # Config files
        elif any(path.endswith(ext) for ext in FILE_CATEGORIES["config"]):
            categories["config"].append(f["path"])
        # Documentation
        elif any(path.endswith(ext) for ext in FILE_CATEGORIES["documentation"]):
            categories["documentation"].append(f["path"])
        # Source code
        elif any(path.endswith(ext) for exts in [FILE_CATEGORIES["python"], FILE_CATEGORIES["javascript"], FILE_CATEGORIES["typescript"]] for ext in exts):
            categories["source"].append(f["path"])
        else:
            categories["other"].append(f["path"])
    
    result = {
        "categories": categories,
        "counts": {k: len(v) for k, v in categories.items()},
        "primary_type": max(categories.items(), key=lambda x: len(x[1]))[0] if any(categories.values()) else "unknown",
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="detect_architectural_pattern",
    description="Detect architectural patterns from directory structure",
    input_schema={
        "type": "object",
        "properties": {
            "directories": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of directory paths"
            },
            "files": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of file paths"
            }
        },
        "required": ["directories"]
    }
)
async def detect_architectural_pattern(args: dict) -> dict:
    """Detect architectural patterns from structure."""
    directories = [d.lower() for d in args["directories"]]
    files = [f.lower() for f in args.get("files", [])]
    
    detected = []
    
    for pattern_name, indicators in ARCHITECTURAL_PATTERNS.items():
        evidence = []
        confidence = 0.0
        
        # Check directories
        if "dirs" in indicators:
            for dir_pattern in indicators["dirs"]:
                if any(dir_pattern in d for d in directories):
                    evidence.append(f"Directory '{dir_pattern}' found")
                    confidence += 0.3 / len(indicators["dirs"])
        
        # Check files
        if "files" in indicators:
            for file_pattern in indicators["files"]:
                if any(file_pattern in f for f in files):
                    evidence.append(f"File '{file_pattern}' found")
                    confidence += 0.2 / len(indicators["files"])
        
        if confidence >= 0.2:
            detected.append({
                "pattern": pattern_name,
                "confidence": min(confidence, 1.0),
                "evidence": evidence,
            })
    
    detected.sort(key=lambda x: x["confidence"], reverse=True)
    
    result = {
        "patterns": detected,
        "primary_pattern": detected[0] if detected else None,
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="detect_design_patterns",
    description="Detect design patterns from code content",
    input_schema={
        "type": "object",
        "properties": {
            "code_content": {
                "type": "string",
                "description": "Code content to analyze"
            },
            "file_path": {
                "type": "string",
                "description": "Path of the file being analyzed"
            }
        },
        "required": ["code_content"]
    }
)
async def detect_design_patterns(args: dict) -> dict:
    """Detect design patterns in code."""
    code = args["code_content"]
    file_path = args.get("file_path", "unknown")
    
    detected = []
    
    for pattern_name, signatures in DESIGN_PATTERNS.items():
        matches = []
        for sig in signatures:
            if sig.lower() in code.lower():
                matches.append(sig)
        
        if matches:
            detected.append({
                "pattern": pattern_name,
                "file": file_path,
                "signatures_found": matches,
                "confidence": min(len(matches) / len(signatures), 1.0),
            })
    
    result = {
        "patterns": detected,
        "file": file_path,
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="identify_entry_points",
    description="Identify application entry points from file list",
    input_schema={
        "type": "object",
        "properties": {
            "files": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of file paths"
            }
        },
        "required": ["files"]
    }
)
async def identify_entry_points(args: dict) -> dict:
    """Identify entry points in the codebase."""
    files = args["files"]
    
    entry_point_patterns = [
        "main.py", "__main__.py", "app.py", "server.py", "wsgi.py", "asgi.py",
        "manage.py", "cli.py", "run.py", "index.py",
        "index.ts", "index.js", "main.ts", "main.js",
        "App.tsx", "App.jsx",
    ]
    
    entry_points = []
    
    for f in files:
        filename = f.split("/")[-1]
        if filename in entry_point_patterns:
            entry_points.append({
                "path": f,
                "type": "primary" if filename in ["main.py", "__main__.py", "index.ts", "index.js"] else "secondary",
            })
    
    result = {
        "entry_points": entry_points,
        "count": len(entry_points),
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}


@tool(
    name="extract_imports",
    description="Extract import statements from Python code",
    input_schema={
        "type": "object",
        "properties": {
            "code_content": {
                "type": "string",
                "description": "Python code content"
            }
        },
        "required": ["code_content"]
    }
)
async def extract_imports(args: dict) -> dict:
    """Extract imports from Python code."""
    code = args["code_content"]
    
    imports = []
    
    # Match import statements
    import_pattern = r'^(?:from\s+(\S+)\s+)?import\s+(.+)$'
    
    for line in code.split("\n"):
        line = line.strip()
        match = re.match(import_pattern, line)
        if match:
            from_module = match.group(1)
            import_items = match.group(2)
            
            if from_module:
                imports.append({
                    "type": "from",
                    "module": from_module,
                    "items": [i.strip().split(" as ")[0] for i in import_items.split(",")],
                })
            else:
                for item in import_items.split(","):
                    imports.append({
                        "type": "import",
                        "module": item.strip().split(" as ")[0],
                    })
    
    # Separate internal vs external
    external = [i for i in imports if not i["module"].startswith(".")]
    internal = [i for i in imports if i["module"].startswith(".")]
    
    result = {
        "imports": imports,
        "external_count": len(external),
        "internal_count": len(internal),
        "external_modules": list(set(i["module"].split(".")[0] for i in external)),
    }
    
    return {"content": [{"type": "text", "text": str(result)}]}
```

### Task 3: Create Repo Analyzer Agent

**File**: `src/codestory/agents/analyzer/agent.py`

```python
"""Repo Analyzer Agent using Claude Agent SDK patterns."""

from claude_agent_sdk import (
    tool,
    create_sdk_mcp_server,
    ClaudeAgentOptions,
    ClaudeSDKClient,
    AgentDefinition,
)

from .tools.github import (
    fetch_repository_tree,
    fetch_file_content,
    fetch_repository_metadata,
    parse_github_url,
)
from .tools.analysis import (
    categorize_files,
    detect_architectural_pattern,
    detect_design_patterns,
    identify_entry_points,
    extract_imports,
)


REPO_ANALYZER_PROMPT = """You are the Repository Analyzer Agent for Code Story.

Your role is to thoroughly analyze a code repository to extract:
1. Project structure and file organization
2. Key components and their responsibilities
3. Architectural patterns and design decisions
4. Dependencies and their relationships
5. Entry points and data flow

## Analysis Process

When given a repository URL, follow this systematic approach:

**Phase 1: Repository Overview**
1. Use parse_github_url to extract owner/repo
2. Use fetch_repository_metadata to get project info
3. Use fetch_repository_tree to get file structure

**Phase 2: Structure Analysis**
1. Use categorize_files to organize files by type
2. Use identify_entry_points to find main files
3. Use detect_architectural_pattern to identify architecture

**Phase 3: Code Deep Dive**
1. Use fetch_file_content to read key files
2. Use extract_imports to map dependencies
3. Use detect_design_patterns on important files

## Focus on Story Plan

If a story_plan is provided, prioritize analysis based on intent:
- For "onboarding" intent: Focus on entry points and getting started
- For "architecture" intent: Deep dive into system design
- For "feature" intent: Analyze specific feature code paths
- For "debugging" intent: Trace execution flows

## Output Format

Your analysis should produce structured data including:
- File tree with annotations
- List of key components with descriptions
- Identified patterns and their locations
- Dependency relationships
- Recommended reading order for understanding

Be thorough but efficient - don't analyze every file in detail.
Prioritize files based on the story plan focus areas."""


# Create MCP server with analyzer tools
analyzer_mcp_server = create_sdk_mcp_server(
    name="analyzer",
    version="1.0.0",
    tools=[
        # GitHub tools
        fetch_repository_tree,
        fetch_file_content,
        fetch_repository_metadata,
        parse_github_url,
        # Analysis tools
        categorize_files,
        detect_architectural_pattern,
        detect_design_patterns,
        identify_entry_points,
        extract_imports,
    ]
)


def create_repo_analyzer_options() -> ClaudeAgentOptions:
    """Create ClaudeAgentOptions with Repo Analyzer configuration."""
    return ClaudeAgentOptions(
        mcp_servers={"analyzer": analyzer_mcp_server},
        agents={
            "repo-analyzer": AgentDefinition(
                description="Analyzes repository structure, patterns, and key components",
                prompt=REPO_ANALYZER_PROMPT,
                tools=[
                    "mcp__analyzer__parse_github_url",
                    "mcp__analyzer__fetch_repository_tree",
                    "mcp__analyzer__fetch_file_content",
                    "mcp__analyzer__fetch_repository_metadata",
                    "mcp__analyzer__categorize_files",
                    "mcp__analyzer__detect_architectural_pattern",
                    "mcp__analyzer__detect_design_patterns",
                    "mcp__analyzer__identify_entry_points",
                    "mcp__analyzer__extract_imports",
                ],
                model="opus",  # Use Opus for complex code analysis
            )
        }
    )


class RepoAnalyzerAgent:
    """High-level wrapper for Repo Analyzer operations."""
    
    def __init__(self):
        self.options = create_repo_analyzer_options()
        self.client = ClaudeSDKClient(self.options)
        self.current_analysis = None
        self.analyzed_files = []
    
    async def analyze_repository(
        self,
        repo_url: str,
        story_plan: dict | None = None,
        focus_areas: list[str] | None = None,
    ) -> dict:
        """Analyze a repository based on the story plan.
        
        Args:
            repo_url: GitHub repository URL
            story_plan: Story plan from Intent Agent
            focus_areas: Specific areas to focus on
        
        Returns:
            Complete repository analysis
        """
        prompt = f"Analyze this repository: {repo_url}\n\n"
        
        if story_plan:
            prompt += f"Story Plan:\n"
            prompt += f"- Intent: {story_plan.get('intent_category', 'general')}\n"
            prompt += f"- Expertise: {story_plan.get('expertise_level', 'intermediate')}\n"
            prompt += f"- Style: {story_plan.get('narrative_style', 'documentary')}\n"
        
        if focus_areas:
            prompt += f"\nFocus areas: {', '.join(focus_areas)}\n"
        
        prompt += "\nPlease analyze this repository thoroughly."
        
        response = await self.client.run_agent(
            agent_name="repo-analyzer",
            message=prompt,
        )
        
        return {"analysis": response, "repo_url": repo_url}
    
    async def analyze_specific_file(self, repo_url: str, file_path: str) -> dict:
        """Analyze a specific file in detail."""
        prompt = f"Analyze this specific file in detail:\nRepository: {repo_url}\nFile: {file_path}"
        
        response = await self.client.run_agent(
            agent_name="repo-analyzer",
            message=prompt,
        )
        
        self.analyzed_files.append(file_path)
        return {"file_analysis": response, "path": file_path}
    
    def get_analysis_summary(self) -> dict:
        """Get summary of current analysis state."""
        return {
            "files_analyzed": len(self.analyzed_files),
            "analyzed_files": self.analyzed_files.copy(),
            "has_analysis": self.current_analysis is not None,
        }
```

### Task 4: Create Package Structure

**File**: `src/codestory/agents/analyzer/__init__.py`

```python
"""Repo Analyzer Agent package using Claude Agent SDK."""

from .tools.github import (
    fetch_repository_tree,
    fetch_file_content,
    fetch_repository_metadata,
    parse_github_url,
)
from .tools.analysis import (
    categorize_files,
    detect_architectural_pattern,
    detect_design_patterns,
    identify_entry_points,
    extract_imports,
)
from .agent import (
    RepoAnalyzerAgent,
    analyzer_mcp_server,
    create_repo_analyzer_options,
    REPO_ANALYZER_PROMPT,
)

__all__ = [
    # GitHub tools
    "fetch_repository_tree",
    "fetch_file_content",
    "fetch_repository_metadata",
    "parse_github_url",
    # Analysis tools
    "categorize_files",
    "detect_architectural_pattern",
    "detect_design_patterns",
    "identify_entry_points",
    "extract_imports",
    # Agent
    "RepoAnalyzerAgent",
    "analyzer_mcp_server",
    "create_repo_analyzer_options",
    "REPO_ANALYZER_PROMPT",
]
```

**File**: `src/codestory/agents/analyzer/tools/__init__.py`

```python
"""Analyzer tools package."""
```

## Verification

```bash
uv run python -c "from codestory.agents.analyzer import RepoAnalyzerAgent; print('Analyzer OK')"
```

## Success Criteria

- Repo Analyzer uses @tool decorator for all tools
- AgentDefinition uses `opus` model for deep code analysis
- MCP server created with create_sdk_mcp_server
- Tool names follow mcp__analyzer__<tool> pattern
- Can fetch and analyze GitHub repositories

## Next Step

Proceed to 03-02-PLAN.md for advanced analysis capabilities.
