# Plan 03-03: Caching and Pipeline Integration

## Overview

**Phase**: 3 - Repo Analyzer Agent
**Plan**: 03 of 05
**Depends on**: 03-01 (Core Setup), 03-02 (Analysis Tools)
**Enables**: 03-04 (Pattern Recognition)

## Goal

Implement caching layer for repository analysis results and integrate the Repo Analyzer Agent into the pipeline using Claude Agent SDK's `AgentDefinition` pattern.

## Claude Agent SDK Pattern

The Repo Analyzer Agent uses `AgentDefinition` for pipeline integration:

```python
from claude_agent_sdk import AgentDefinition, ClaudeAgentOptions

AgentDefinition(
    description="Analyzes repository structure, patterns, and key components",
    prompt=REPO_ANALYZER_PROMPT,
    tools=["mcp__analyzer__*"],
    model="opus",  # Complex code analysis
)
```

## Tasks

### Task 1: Create Analysis Cache Layer

**File**: `src/codestory/cache/analysis.py`

```python
"""Analysis caching layer for repository data.

Caches expensive analysis results to Redis for fast retrieval.
"""

import json
import hashlib
from datetime import timedelta
from typing import Any

from redis.asyncio import Redis

from codestory.core.config import get_settings


class AnalysisCache:
    """Cache for repository analysis results."""

    # Cache TTL settings
    TREE_TTL = timedelta(hours=1)        # Repository tree changes frequently
    METADATA_TTL = timedelta(hours=24)   # Metadata rarely changes
    ANALYSIS_TTL = timedelta(hours=6)    # Full analysis - moderate TTL
    CONTENT_TTL = timedelta(hours=2)     # File content - shorter TTL

    def __init__(self, redis: Redis | None = None):
        self._redis = redis
        self._settings = get_settings()

    async def _get_redis(self) -> Redis:
        """Get or create Redis connection."""
        if self._redis is None:
            self._redis = Redis.from_url(
                self._settings.redis_url,
                decode_responses=True,
            )
        return self._redis

    def _make_key(self, prefix: str, *parts: str) -> str:
        """Create cache key from parts."""
        key_content = ":".join(parts)
        return f"codestory:{prefix}:{key_content}"

    def _hash_content(self, content: str) -> str:
        """Create hash of content for cache key."""
        return hashlib.sha256(content.encode()).hexdigest()[:16]

    async def get_tree(self, repo_url: str, ref: str = "main") -> list[str] | None:
        """Get cached repository tree."""
        redis = await self._get_redis()
        key = self._make_key("tree", repo_url, ref)
        data = await redis.get(key)
        return json.loads(data) if data else None

    async def set_tree(
        self,
        repo_url: str,
        tree: list[str],
        ref: str = "main",
    ) -> None:
        """Cache repository tree."""
        redis = await self._get_redis()
        key = self._make_key("tree", repo_url, ref)
        await redis.setex(key, self.TREE_TTL, json.dumps(tree))

    async def get_metadata(self, repo_url: str) -> dict[str, Any] | None:
        """Get cached repository metadata."""
        redis = await self._get_redis()
        key = self._make_key("metadata", repo_url)
        data = await redis.get(key)
        return json.loads(data) if data else None

    async def set_metadata(self, repo_url: str, metadata: dict) -> None:
        """Cache repository metadata."""
        redis = await self._get_redis()
        key = self._make_key("metadata", repo_url)
        await redis.setex(key, self.METADATA_TTL, json.dumps(metadata))

    async def get_analysis(
        self,
        repo_url: str,
        analysis_type: str = "full",
    ) -> dict[str, Any] | None:
        """Get cached analysis result."""
        redis = await self._get_redis()
        key = self._make_key("analysis", repo_url, analysis_type)
        data = await redis.get(key)
        return json.loads(data) if data else None

    async def set_analysis(
        self,
        repo_url: str,
        analysis: dict,
        analysis_type: str = "full",
    ) -> None:
        """Cache analysis result."""
        redis = await self._get_redis()
        key = self._make_key("analysis", repo_url, analysis_type)
        await redis.setex(key, self.ANALYSIS_TTL, json.dumps(analysis))

    async def get_file_content(
        self,
        repo_url: str,
        file_path: str,
        ref: str = "main",
    ) -> str | None:
        """Get cached file content."""
        redis = await self._get_redis()
        key = self._make_key("file", repo_url, ref, file_path)
        return await redis.get(key)

    async def set_file_content(
        self,
        repo_url: str,
        file_path: str,
        content: str,
        ref: str = "main",
    ) -> None:
        """Cache file content."""
        redis = await self._get_redis()
        key = self._make_key("file", repo_url, ref, file_path)
        await redis.setex(key, self.CONTENT_TTL, content)

    async def invalidate_repo(self, repo_url: str) -> int:
        """Invalidate all cached data for a repository."""
        redis = await self._get_redis()
        pattern = self._make_key("*", repo_url, "*")
        keys = []
        async for key in redis.scan_iter(match=pattern):
            keys.append(key)
        if keys:
            return await redis.delete(*keys)
        return 0

    async def close(self) -> None:
        """Close Redis connection."""
        if self._redis:
            await self._redis.close()
            self._redis = None


# Global cache instance
_cache: AnalysisCache | None = None


def get_analysis_cache() -> AnalysisCache:
    """Get global cache instance."""
    global _cache
    if _cache is None:
        _cache = AnalysisCache()
    return _cache
```

### Task 2: Create Pipeline Stage for Repo Analyzer

**File**: `src/codestory/agents/stages.py`

```python
"""Pipeline stages for Code Story agent orchestration.

Uses Claude Agent SDK AgentDefinition for subagent configuration.
"""

from typing import Any

from claude_agent_sdk import AgentDefinition, ClaudeAgentOptions, query

from codestory.tools import create_analyzer_mcp_server
from codestory.cache.analysis import get_analysis_cache


# Repo Analyzer Agent prompt
REPO_ANALYZER_PROMPT = """You are the Repo Analyzer Agent for Code Story.

Your role is to analyze GitHub repositories and extract insights for narrative generation.

## Available Tools

You have access to these analysis tools:
- parse_github_url: Extract owner/repo from GitHub URL
- fetch_repository_tree: Get all files in the repository
- fetch_file_content: Read specific file contents
- fetch_repository_metadata: Get repository description, stars, language
- analyze_repository_structure: Analyze architecture and patterns
- identify_story_components: Find narrative-worthy components
- generate_analysis_summary: Create human-readable summary

## Analysis Process

1. Parse the GitHub URL to extract repository info
2. Fetch repository metadata and file tree
3. Identify key files (entry points, config, core modules)
4. Analyze architecture patterns and frameworks
5. Identify story-worthy components based on user intent
6. Generate summary for Story Architect Agent

## Output Format

Return a complete analysis including:
- Repository metadata (name, description, language)
- Architecture pattern detected
- Key components for story chapters
- Recommended narrative focus areas
- Summary for the next pipeline stage

Be thorough in analysis. The Story Architect depends on comprehensive insights."""


def create_repo_analyzer_agent() -> AgentDefinition:
    """Create Repo Analyzer Agent definition."""
    return AgentDefinition(
        description="Analyzes GitHub repositories for structure, patterns, and story-worthy components",
        prompt=REPO_ANALYZER_PROMPT,
        tools=[
            "mcp__analyzer__parse_github_url",
            "mcp__analyzer__fetch_repository_tree",
            "mcp__analyzer__fetch_file_content",
            "mcp__analyzer__fetch_repository_metadata",
            "mcp__analyzer__analyze_repository_structure",
            "mcp__analyzer__identify_story_components",
            "mcp__analyzer__generate_analysis_summary",
        ],
        model="opus",  # Use Opus for complex code analysis reasoning
    )


async def run_analyzer_stage(
    github_url: str,
    intent: dict[str, Any] | None = None,
    use_cache: bool = True,
) -> dict[str, Any]:
    """Run the Repo Analyzer pipeline stage.

    Args:
        github_url: GitHub repository URL to analyze
        intent: Optional user intent from Intent Agent
        use_cache: Whether to use cached results

    Returns:
        Analysis results for Story Architect
    """
    cache = get_analysis_cache()

    # Check cache first
    if use_cache:
        cached = await cache.get_analysis(github_url)
        if cached:
            return {
                "analysis": cached,
                "from_cache": True,
                "github_url": github_url,
            }

    # Build analysis prompt
    focus = ""
    if intent:
        category = intent.get("category", "general_onboarding")
        focus_areas = intent.get("focus_areas", [])
        focus = f"\nUser Intent: {category}\nFocus Areas: {', '.join(focus_areas)}"

    prompt = f"""Analyze this GitHub repository for Code Story.

Repository: {github_url}
{focus}

Steps:
1. Parse the URL and fetch repository metadata
2. Get the file tree and identify key files
3. Analyze architecture and patterns
4. Identify components for narrative chapters
5. Generate a comprehensive summary

Return the complete analysis for the Story Architect Agent."""

    # Create agent options with MCP server
    mcp_server = create_analyzer_mcp_server()
    agent = create_repo_analyzer_agent()

    options = ClaudeAgentOptions(
        mcp_servers={"analyzer": mcp_server},
        agents={"repo_analyzer": agent},
        allowed_tools=agent.tools,
        max_turns=15,  # Allow multiple tool calls for thorough analysis
    )

    # Run analysis
    result_text = ""
    async for message in query(prompt=prompt, options=options):
        if hasattr(message, "content"):
            for block in message.content:
                if hasattr(block, "text"):
                    result_text = block.text

    # Parse and cache result
    try:
        import json
        analysis = json.loads(result_text)
    except json.JSONDecodeError:
        analysis = {"raw_response": result_text}

    if use_cache:
        await cache.set_analysis(github_url, analysis)

    return {
        "analysis": analysis,
        "from_cache": False,
        "github_url": github_url,
        "intent": intent,
    }
```

### Task 3: Create Cache Package Init

**File**: `src/codestory/cache/__init__.py`

```python
"""Caching layer for Code Story.

Provides Redis-backed caching for analysis results.
"""

from codestory.cache.analysis import (
    AnalysisCache,
    get_analysis_cache,
)

__all__ = [
    "AnalysisCache",
    "get_analysis_cache",
]
```

### Task 4: Create Cache Tests

**File**: `tests/cache/test_analysis_cache.py`

```python
"""Tests for analysis cache layer."""

import pytest
from unittest.mock import AsyncMock, MagicMock

from codestory.cache.analysis import AnalysisCache


@pytest.fixture
def mock_redis():
    """Create mock Redis client."""
    redis = AsyncMock()
    redis.get = AsyncMock(return_value=None)
    redis.setex = AsyncMock()
    redis.delete = AsyncMock(return_value=1)
    redis.scan_iter = AsyncMock(return_value=iter([]))
    return redis


@pytest.fixture
def cache(mock_redis):
    """Create cache with mock Redis."""
    return AnalysisCache(redis=mock_redis)


@pytest.mark.asyncio
async def test_get_tree_miss(cache, mock_redis):
    """Test cache miss for tree."""
    result = await cache.get_tree("https://github.com/owner/repo")
    assert result is None
    mock_redis.get.assert_called_once()


@pytest.mark.asyncio
async def test_set_and_get_tree(cache, mock_redis):
    """Test setting and getting tree."""
    tree = ["src/main.py", "tests/test.py"]

    await cache.set_tree("https://github.com/owner/repo", tree)
    mock_redis.setex.assert_called_once()

    # Simulate cache hit
    mock_redis.get.return_value = '["src/main.py", "tests/test.py"]'
    result = await cache.get_tree("https://github.com/owner/repo")

    assert result == tree


@pytest.mark.asyncio
async def test_get_analysis(cache, mock_redis):
    """Test getting cached analysis."""
    analysis = {
        "name": "test-repo",
        "architecture": "layered",
    }
    mock_redis.get.return_value = '{"name": "test-repo", "architecture": "layered"}'

    result = await cache.get_analysis("https://github.com/owner/repo")

    assert result == analysis


@pytest.mark.asyncio
async def test_invalidate_repo(cache, mock_redis):
    """Test invalidating all repo cache."""
    mock_redis.scan_iter = lambda match: AsyncIterator(["key1", "key2"])

    class AsyncIterator:
        def __init__(self, items):
            self.items = iter(items)

        def __aiter__(self):
            return self

        async def __anext__(self):
            try:
                return next(self.items)
            except StopIteration:
                raise StopAsyncIteration

    # Patch for async iteration
    cache._redis.scan_iter = lambda match: AsyncIterator(["key1", "key2"])

    count = await cache.invalidate_repo("https://github.com/owner/repo")

    assert mock_redis.delete.called
```

### Task 5: Create Pipeline Stage Tests

**File**: `tests/agents/test_stages.py`

```python
"""Tests for pipeline stages."""

import pytest
from unittest.mock import AsyncMock, patch

from codestory.agents.stages import (
    create_repo_analyzer_agent,
    run_analyzer_stage,
)


def test_create_repo_analyzer_agent():
    """Test agent definition creation."""
    agent = create_repo_analyzer_agent()

    assert agent.model == "opus"
    assert "mcp__analyzer__parse_github_url" in agent.tools
    assert "mcp__analyzer__analyze_repository_structure" in agent.tools
    assert len(agent.tools) >= 7


@pytest.mark.asyncio
async def test_run_analyzer_stage_cached():
    """Test stage returns cached result."""
    cached_analysis = {
        "name": "cached-repo",
        "architecture_pattern": "layered",
    }

    with patch("codestory.agents.stages.get_analysis_cache") as mock_cache:
        cache = AsyncMock()
        cache.get_analysis.return_value = cached_analysis
        mock_cache.return_value = cache

        result = await run_analyzer_stage(
            "https://github.com/owner/repo",
            use_cache=True,
        )

        assert result["from_cache"] is True
        assert result["analysis"] == cached_analysis


@pytest.mark.asyncio
async def test_run_analyzer_stage_with_intent():
    """Test stage with user intent."""
    intent = {
        "category": "architecture_understanding",
        "focus_areas": ["api", "database"],
    }

    with patch("codestory.agents.stages.get_analysis_cache") as mock_cache:
        cache = AsyncMock()
        cache.get_analysis.return_value = None
        cache.set_analysis = AsyncMock()
        mock_cache.return_value = cache

        with patch("codestory.agents.stages.query") as mock_query:
            # Mock query response
            async def mock_response(*args, **kwargs):
                class MockMessage:
                    content = [type("Block", (), {"text": '{"analysis": "result"}'})()]
                yield MockMessage()

            mock_query.return_value = mock_response()

            with patch("codestory.agents.stages.create_analyzer_mcp_server"):
                result = await run_analyzer_stage(
                    "https://github.com/owner/repo",
                    intent=intent,
                    use_cache=False,
                )

                assert result["intent"] == intent
```

## Files Created/Modified

| File | Action | Purpose |
|------|--------|---------|
| `src/codestory/cache/__init__.py` | Create | Cache package init |
| `src/codestory/cache/analysis.py` | Create | Redis cache for analysis results |
| `src/codestory/agents/stages.py` | Create | Pipeline stage with AgentDefinition |
| `tests/cache/test_analysis_cache.py` | Create | Cache layer tests |
| `tests/agents/test_stages.py` | Create | Pipeline stage tests |

## Validation Criteria

1. AnalysisCache connects to Redis and caches data
2. Cache keys use consistent naming: `codestory:<type>:<repo>:*`
3. TTLs are appropriate (1-24 hours depending on data volatility)
4. run_analyzer_stage uses AgentDefinition with opus model
5. Cached results bypass agent execution
6. All tests pass

## Integration Points

- **Intent Agent**: Receives intent dict with `category` and `focus_areas`
- **Story Architect**: Provides analysis with components for chapters
- **Cache**: Redis-backed with configurable TTLs

## Tool Naming

Agent tools accessed as: `mcp__analyzer__<tool_name>`

## Model Selection

- **Repo Analyzer**: Uses `opus` model for complex code analysis and pattern recognition

## Next Step

Ready for 03-04-PLAN.md (Pattern Recognition Enhancement)
