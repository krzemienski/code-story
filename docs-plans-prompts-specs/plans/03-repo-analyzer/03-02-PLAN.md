# Plan 03-02: Analysis Extraction Tools

## Overview

**Phase**: 3 - Repo Analyzer Agent
**Plan**: 02 of 05
**Depends on**: 03-01 (Repo Analyzer Core Setup)
**Enables**: 03-03 (Caching and Pipeline Integration)

## Goal

Implement analysis extraction tools using Claude Agent SDK `@tool` decorator pattern. These tools process repository data to extract architecture insights, story components, and analysis summaries for narrative generation.

## Claude Agent SDK Pattern

All tools use the `@tool` decorator pattern:
```python
from claude_agent_sdk import tool

@tool(
    name="tool_name",
    description="What the tool does",
    input_schema={
        "type": "object",
        "properties": {...},
        "required": [...]
    }
)
async def tool_name(args: dict) -> dict:
    return {"content": [{"type": "text", "text": str(result)}]}
```

## Tasks

### Task 1: Create Analysis Extraction Tools

**File**: `src/codestory/tools/analysis.py`

```python
"""Analysis extraction tools for repository understanding.

Uses Claude Agent SDK @tool decorator pattern for LLM tool integration.
"""

import json
from typing import Any

from claude_agent_sdk import tool


@tool(
    name="analyze_repository_structure",
    description="Analyze repository structure to identify architecture patterns, entry points, and module organization",
    input_schema={
        "type": "object",
        "properties": {
            "file_tree": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of file paths in the repository"
            },
            "file_contents": {
                "type": "object",
                "additionalProperties": {"type": "string"},
                "description": "Map of file path to content preview"
            },
            "repo_metadata": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "description": {"type": "string"},
                    "primary_language": {"type": "string"}
                },
                "description": "Basic repository metadata"
            }
        },
        "required": ["file_tree", "repo_metadata"]
    }
)
async def analyze_repository_structure(args: dict) -> dict:
    """Analyze repository structure for architecture insights."""
    file_tree = args.get("file_tree", [])
    file_contents = args.get("file_contents", {})
    repo_metadata = args.get("repo_metadata", {})

    # Detect architecture pattern
    architecture = _detect_architecture_pattern(file_tree)

    # Find entry points
    entry_points = _identify_entry_points(file_tree)

    # Identify core modules
    core_modules = _identify_core_modules(file_tree, file_contents)

    # Detect frameworks
    frameworks = _detect_frameworks(file_tree, file_contents)

    analysis = {
        "name": repo_metadata.get("name", "repository"),
        "description": repo_metadata.get("description"),
        "primary_language": repo_metadata.get("primary_language", "unknown"),
        "architecture_pattern": architecture["pattern"],
        "architecture_description": architecture["description"],
        "entry_points": entry_points,
        "core_modules": core_modules,
        "frameworks": frameworks,
        "total_files": len(file_tree),
    }

    return {"content": [{"type": "text", "text": json.dumps(analysis, indent=2)}]}


@tool(
    name="identify_story_components",
    description="Identify components suitable for story chapters based on repository analysis",
    input_schema={
        "type": "object",
        "properties": {
            "analysis": {
                "type": "object",
                "description": "Repository analysis from analyze_repository_structure"
            },
            "intent": {
                "type": "object",
                "description": "Optional user intent to focus the story",
                "properties": {
                    "category": {"type": "string"},
                    "focus_areas": {"type": "array", "items": {"type": "string"}}
                }
            }
        },
        "required": ["analysis"]
    }
)
async def identify_story_components(args: dict) -> dict:
    """Identify components suitable for story chapters."""
    analysis = args.get("analysis", {})
    intent = args.get("intent")

    components = []

    # Entry points are always important
    for entry in analysis.get("entry_points", []):
        components.append({
            "type": "entry_point",
            "path": entry,
            "story_relevance": "high",
            "suggested_chapter": "The Beginning - Where It All Starts",
        })

    # Core modules
    for module in analysis.get("core_modules", []):
        components.append({
            "type": "module",
            "name": module.get("name"),
            "path": module.get("path"),
            "purpose": module.get("purpose"),
            "story_relevance": "high",
            "suggested_chapter": f"The {module.get('name', 'Core')} - Heart of the System",
        })

    # Frameworks make good story elements
    frameworks = analysis.get("frameworks", [])
    if frameworks:
        components.append({
            "type": "dependencies",
            "dependencies": frameworks[:10],
            "story_relevance": "medium",
            "suggested_chapter": "The Allies - Libraries That Power the System",
        })

    # Filter by intent focus if provided
    if intent and intent.get("focus_areas"):
        focus_areas = intent["focus_areas"]
        components = [c for c in components
                      if any(area.lower() in str(c).lower() for area in focus_areas)]

    result = {
        "components": components,
        "architecture_overview": analysis.get("architecture_description"),
        "complexity": _assess_complexity(analysis),
        "total_chapters_suggested": len(components),
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}


@tool(
    name="generate_analysis_summary",
    description="Generate a human-readable summary of repository analysis for quick overview",
    input_schema={
        "type": "object",
        "properties": {
            "analysis": {
                "type": "object",
                "description": "Complete repository analysis"
            },
            "story_components": {
                "type": "object",
                "description": "Story components from identify_story_components"
            }
        },
        "required": ["analysis"]
    }
)
async def generate_analysis_summary(args: dict) -> dict:
    """Generate human-readable analysis summary."""
    analysis = args.get("analysis", {})
    story_components = args.get("story_components", {})

    # Build summary
    name = analysis.get("name", "Repository")
    language = analysis.get("primary_language", "unknown")
    architecture = analysis.get("architecture_pattern", "unknown")
    file_count = analysis.get("total_files", 0)
    frameworks = analysis.get("frameworks", [])

    summary_points = [
        f"A {language} project with {file_count} files",
        f"Following {architecture} architectural pattern",
    ]

    if frameworks:
        summary_points.append(f"Built with {', '.join(frameworks[:3])}")

    entry_points = analysis.get("entry_points", [])
    core_modules = analysis.get("core_modules", [])
    if entry_points or core_modules:
        summary_points.append(
            f"{len(entry_points)} entry point(s) and {len(core_modules)} core modules"
        )

    chapters = story_components.get("total_chapters_suggested", 0)
    if chapters:
        summary_points.append(f"Suggested story structure: {chapters} chapters")

    result = {
        "repo_name": name,
        "one_line": summary_points[0] if summary_points else "Repository analyzed",
        "summary_points": summary_points,
        "key_stats": {
            "files": file_count,
            "language": language,
            "architecture": architecture,
            "frameworks": len(frameworks),
        },
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}


# Helper functions

def _detect_architecture_pattern(file_tree: list[str]) -> dict[str, str]:
    """Detect architecture pattern from file structure."""
    dirs = set(path.split("/")[0].lower() for path in file_tree if "/" in path)

    patterns = [
        ({"models", "views", "controllers"}, "mvc", "Model-View-Controller pattern"),
        ({"domain", "application", "infrastructure"}, "clean", "Clean Architecture"),
        ({"adapters", "ports", "domain"}, "hexagonal", "Hexagonal/Ports & Adapters"),
        ({"api", "services", "models"}, "layered", "Layered architecture"),
        ({"src", "lib", "tests"}, "standard", "Standard project structure"),
    ]

    for indicators, pattern, description in patterns:
        if indicators & dirs:
            return {"pattern": pattern, "description": description}

    return {"pattern": "monolith", "description": "Monolithic application structure"}


def _identify_entry_points(file_tree: list[str]) -> list[str]:
    """Identify application entry points."""
    entry_patterns = [
        "main.py", "__main__.py", "app.py", "server.py", "cli.py",
        "index.ts", "index.js", "main.ts", "main.js",
        "manage.py", "wsgi.py", "asgi.py",
    ]

    return [
        path for path in file_tree
        if any(path.endswith(pattern) or path.endswith("/" + pattern)
               for pattern in entry_patterns)
    ]


def _identify_core_modules(file_tree: list[str], contents: dict) -> list[dict]:
    """Identify core modules based on structure and imports."""
    core_dirs = ["src", "lib", "core", "app", "api", "services"]

    modules = []
    seen_modules = set()

    for path in file_tree:
        parts = path.split("/")
        if len(parts) >= 2:
            dir_name = parts[0].lower()
            if dir_name in core_dirs and dir_name not in seen_modules:
                modules.append({
                    "name": parts[1] if len(parts) > 1 else dir_name,
                    "path": "/".join(parts[:2]),
                    "purpose": f"Core {dir_name} module",
                })
                seen_modules.add(dir_name)

    return modules[:10]


def _detect_frameworks(file_tree: list[str], contents: dict) -> list[str]:
    """Detect frameworks from config files and imports."""
    frameworks = []

    # Check for common framework indicators
    framework_files = {
        "fastapi": ["requirements.txt", "pyproject.toml"],
        "django": ["manage.py", "settings.py"],
        "flask": ["app.py", "requirements.txt"],
        "react": ["package.json"],
        "next": ["next.config.js", "next.config.ts"],
        "express": ["package.json"],
    }

    file_set = set(path.lower() for path in file_tree)

    for framework, indicators in framework_files.items():
        for indicator in indicators:
            if any(indicator in f for f in file_set):
                if framework not in frameworks:
                    frameworks.append(framework)
                break

    return frameworks


def _assess_complexity(analysis: dict) -> str:
    """Assess repository complexity."""
    file_count = analysis.get("total_files", 0)
    module_count = len(analysis.get("core_modules", []))

    if file_count > 200 or module_count > 10:
        return "high"
    elif file_count > 50 or module_count > 5:
        return "medium"
    return "low"
```

### Task 2: Update MCP Server with Analysis Tools

**File**: `src/codestory/tools/__init__.py`

Update the tools package to include analysis tools:

```python
"""Code Story MCP Tools Package.

Provides tools using Claude Agent SDK @tool decorator pattern.
"""

from claude_agent_sdk import create_sdk_mcp_server

from codestory.tools.github import (
    parse_github_url,
    fetch_repository_tree,
    fetch_file_content,
    fetch_repository_metadata,
)
from codestory.tools.analysis import (
    analyze_repository_structure,
    identify_story_components,
    generate_analysis_summary,
)


def create_analyzer_mcp_server():
    """Create MCP server with all repo analyzer tools."""
    return create_sdk_mcp_server(
        name="analyzer",
        version="1.0.0",
        tools=[
            # GitHub tools
            parse_github_url,
            fetch_repository_tree,
            fetch_file_content,
            fetch_repository_metadata,
            # Analysis tools
            analyze_repository_structure,
            identify_story_components,
            generate_analysis_summary,
        ],
    )


__all__ = [
    # GitHub tools
    "parse_github_url",
    "fetch_repository_tree",
    "fetch_file_content",
    "fetch_repository_metadata",
    # Analysis tools
    "analyze_repository_structure",
    "identify_story_components",
    "generate_analysis_summary",
    # MCP server factory
    "create_analyzer_mcp_server",
]
```

### Task 3: Create Analysis Tool Tests

**File**: `tests/tools/test_analysis_tools.py`

```python
"""Tests for analysis extraction tools."""

import pytest
import json

from codestory.tools.analysis import (
    analyze_repository_structure,
    identify_story_components,
    generate_analysis_summary,
)


@pytest.mark.asyncio
async def test_analyze_repository_structure():
    """Test repository structure analysis."""
    args = {
        "file_tree": [
            "src/main.py",
            "src/api/routes.py",
            "src/models/user.py",
            "tests/test_main.py",
            "pyproject.toml",
        ],
        "repo_metadata": {
            "name": "test-repo",
            "description": "A test repository",
            "primary_language": "python",
        },
    }

    result = await analyze_repository_structure(args)

    assert "content" in result
    analysis = json.loads(result["content"][0]["text"])

    assert analysis["name"] == "test-repo"
    assert analysis["primary_language"] == "python"
    assert analysis["total_files"] == 5
    assert "architecture_pattern" in analysis


@pytest.mark.asyncio
async def test_identify_story_components():
    """Test story component identification."""
    args = {
        "analysis": {
            "name": "test-repo",
            "entry_points": ["src/main.py"],
            "core_modules": [
                {"name": "api", "path": "src/api", "purpose": "API layer"}
            ],
            "frameworks": ["fastapi"],
            "architecture_description": "Standard layered architecture",
        }
    }

    result = await identify_story_components(args)

    assert "content" in result
    components = json.loads(result["content"][0]["text"])

    assert len(components["components"]) >= 2
    assert components["total_chapters_suggested"] >= 2


@pytest.mark.asyncio
async def test_generate_analysis_summary():
    """Test summary generation."""
    args = {
        "analysis": {
            "name": "test-repo",
            "primary_language": "python",
            "architecture_pattern": "layered",
            "total_files": 50,
            "frameworks": ["fastapi", "sqlalchemy"],
            "entry_points": ["main.py"],
            "core_modules": [{"name": "api"}, {"name": "db"}],
        }
    }

    result = await generate_analysis_summary(args)

    assert "content" in result
    summary = json.loads(result["content"][0]["text"])

    assert summary["repo_name"] == "test-repo"
    assert "one_line" in summary
    assert len(summary["summary_points"]) >= 2
```

## Files Created/Modified

| File | Action | Purpose |
|------|--------|---------|
| `src/codestory/tools/analysis.py` | Create | Analysis extraction tools with @tool decorators |
| `src/codestory/tools/__init__.py` | Update | Export analysis tools and update MCP server |
| `tests/tools/test_analysis_tools.py` | Create | Tests for analysis tools |

## Validation Criteria

1. All tools use `@tool` decorator with proper input_schema
2. Tools return `{"content": [{"type": "text", "text": ...}]}` format
3. analyze_repository_structure detects architecture patterns
4. identify_story_components maps analysis to narrative chapters
5. generate_analysis_summary produces readable summaries
6. All tests pass with `pytest tests/tools/test_analysis_tools.py`

## Tool Naming Convention

Tools are accessed as: `mcp__analyzer__<tool_name>`
- `mcp__analyzer__analyze_repository_structure`
- `mcp__analyzer__identify_story_components`
- `mcp__analyzer__generate_analysis_summary`

## Next Step

Ready for 03-03-PLAN.md (Caching and Pipeline Integration)
