# Plan 05-04: Audio Assembly

## Overview

**Phase**: 5 - Voice Director Agent
**Plan**: 04 of 04
**Depends on**: 05-01 (ElevenLabs API), 05-02 (Voice Director), 05-03 (Script Preparation)
**Enables**: 06-01 (FastAPI Backend)

## Goal

Implement audio assembly tools that combine synthesized segments into chapter files and complete stories with proper metadata for podcast players and audio apps.

## Claude Agent SDK Pattern

Audio assembly uses `@tool` decorator for pydub-based audio processing:

```python
from claude_agent_sdk import tool, create_sdk_mcp_server

@tool(
    name="assemble_chapter",
    description="Assemble audio segments into a chapter",
    input_schema={
        "type": "object",
        "properties": {
            "segment_files": {
                "type": "array",
                "items": {"type": "object"},
                "description": "List of segment info with file_path and pause_before",
            },
            "chapter_number": {"type": "integer"},
            "chapter_title": {"type": "string"},
            "output_path": {"type": "string"},
        },
        "required": ["segment_files", "chapter_number", "chapter_title", "output_path"],
    },
)
async def assemble_chapter(args: dict) -> dict:
    # Implementation
    return {"content": [{"type": "text", "text": json.dumps(result)}]}
```

## Tasks

### Task 1: Create Audio Assembly Tools

**File**: `src/codestory/skills/voice/assembly.py`

```python
"""Audio assembly tools for Code Story.

Uses Claude Agent SDK @tool decorator for pydub-based audio processing.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Any

from pydub import AudioSegment

from claude_agent_sdk import tool


# Audio processing constants
DEFAULT_BITRATE = "192k"
DEFAULT_FORMAT = "mp3"
TARGET_DBFS = -20.0
FADE_IN_MS = 100
FADE_OUT_MS = 100
CHAPTER_SILENCE_MS = 2000
INTRO_SILENCE_MS = 1000


def _create_silence(duration_ms: int) -> AudioSegment:
    """Create silence of specified duration."""
    return AudioSegment.silent(duration=duration_ms)


def _load_audio_file(file_path: str) -> AudioSegment:
    """Load an audio file."""
    return AudioSegment.from_file(file_path)


def _normalize_audio(audio: AudioSegment, target_dbfs: float = TARGET_DBFS) -> AudioSegment:
    """Normalize audio to target dBFS."""
    if audio.dBFS == float("-inf"):
        return audio  # Silent audio, can't normalize
    change_in_dbfs = target_dbfs - audio.dBFS
    return audio.apply_gain(change_in_dbfs)


def _add_fade(
    audio: AudioSegment,
    fade_in_ms: int = FADE_IN_MS,
    fade_out_ms: int = FADE_OUT_MS,
) -> AudioSegment:
    """Add fade in/out to audio."""
    return audio.fade_in(fade_in_ms).fade_out(fade_out_ms)


def _format_duration(ms: int) -> str:
    """Format duration as HH:MM:SS or MM:SS."""
    seconds = ms // 1000
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60

    if hours > 0:
        return f"{hours}:{minutes:02d}:{secs:02d}"
    return f"{minutes}:{secs:02d}"


@tool(
    name="assemble_chapter",
    description="Assemble audio segments into a single chapter file with transitions and normalization",
    input_schema={
        "type": "object",
        "properties": {
            "segment_files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string", "description": "Path to audio file"},
                        "pause_before_seconds": {
                            "type": "number",
                            "description": "Silence before segment in seconds",
                        },
                        "segment_index": {"type": "integer", "description": "Original segment index"},
                    },
                    "required": ["file_path"],
                },
                "description": "List of segment info with file paths",
            },
            "chapter_number": {"type": "integer", "description": "Chapter number (1-based)"},
            "chapter_title": {"type": "string", "description": "Chapter title for metadata"},
            "output_path": {"type": "string", "description": "Path for output MP3 file"},
            "include_transitions": {
                "type": "boolean",
                "description": "Whether to include pause transitions",
                "default": True,
            },
            "normalize": {
                "type": "boolean",
                "description": "Whether to normalize audio levels",
                "default": True,
            },
        },
        "required": ["segment_files", "chapter_number", "chapter_title", "output_path"],
    },
)
async def assemble_chapter(args: dict) -> dict:
    """Assemble audio segments into a single chapter file."""
    segment_files = args["segment_files"]
    chapter_number = args["chapter_number"]
    chapter_title = args["chapter_title"]
    output_path = args["output_path"]
    include_transitions = args.get("include_transitions", True)
    normalize = args.get("normalize", True)

    chapter_audio = AudioSegment.empty()
    segments_included = []

    for seg in segment_files:
        file_path = seg.get("file_path")
        if not file_path:
            continue

        pause_before = seg.get("pause_before_seconds", 0) * 1000  # Convert to ms

        # Add silence before if specified
        if pause_before > 0 and include_transitions:
            chapter_audio += _create_silence(int(pause_before))

        # Load and add segment
        segment_audio = _load_audio_file(file_path)

        if normalize:
            segment_audio = _normalize_audio(segment_audio)

        chapter_audio += segment_audio
        segments_included.append(seg.get("segment_index", len(segments_included)))

    # Add fade in/out
    chapter_audio = _add_fade(chapter_audio)

    # Export
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    chapter_audio.export(str(output_file), format=DEFAULT_FORMAT, bitrate=DEFAULT_BITRATE)

    result = {
        "chapter_number": chapter_number,
        "title": chapter_title,
        "file_path": str(output_file),
        "duration_ms": len(chapter_audio),
        "duration_seconds": len(chapter_audio) / 1000,
        "duration_formatted": _format_duration(len(chapter_audio)),
        "segments_included": segments_included,
        "segment_count": len(segments_included),
        "file_size_bytes": output_file.stat().st_size,
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}


@tool(
    name="assemble_complete_story",
    description="Assemble all chapters into a complete story audio file with chapter markers",
    input_schema={
        "type": "object",
        "properties": {
            "chapter_files": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "file_path": {"type": "string"},
                        "chapter_number": {"type": "integer"},
                        "title": {"type": "string"},
                    },
                    "required": ["file_path"],
                },
                "description": "List of chapter info from assemble_chapter",
            },
            "story_title": {"type": "string", "description": "Title of the complete story"},
            "output_path": {"type": "string", "description": "Path for complete story file"},
            "add_chapter_markers": {
                "type": "boolean",
                "description": "Whether to track chapter positions for podcast apps",
                "default": True,
            },
        },
        "required": ["chapter_files", "story_title", "output_path"],
    },
)
async def assemble_complete_story(args: dict) -> dict:
    """Assemble chapter files into a complete story with markers."""
    chapter_files = args["chapter_files"]
    story_title = args["story_title"]
    output_path = args["output_path"]

    complete_audio = AudioSegment.empty()
    chapters = []
    current_position = 0

    # Add intro silence
    complete_audio += _create_silence(INTRO_SILENCE_MS)
    current_position += INTRO_SILENCE_MS

    for idx, chapter in enumerate(chapter_files):
        chapter_audio = _load_audio_file(chapter["file_path"])

        chapters.append({
            "chapter_number": chapter.get("chapter_number", idx + 1),
            "title": chapter.get("title", f"Chapter {idx + 1}"),
            "start_time_ms": current_position,
            "start_time_seconds": current_position / 1000,
            "duration_ms": len(chapter_audio),
            "duration_seconds": len(chapter_audio) / 1000,
        })

        complete_audio += chapter_audio
        current_position += len(chapter_audio)

        # Add silence between chapters
        complete_audio += _create_silence(CHAPTER_SILENCE_MS)
        current_position += CHAPTER_SILENCE_MS

    # Final fade out
    complete_audio = complete_audio.fade_out(500)

    # Export
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    complete_audio.export(str(output_file), format=DEFAULT_FORMAT, bitrate=DEFAULT_BITRATE)

    result = {
        "title": story_title,
        "file_path": str(output_file),
        "total_duration_ms": len(complete_audio),
        "total_duration_seconds": len(complete_audio) / 1000,
        "total_duration_formatted": _format_duration(len(complete_audio)),
        "chapters": chapters,
        "chapter_count": len(chapters),
        "file_size_bytes": output_file.stat().st_size,
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}


@tool(
    name="generate_audio_metadata",
    description="Generate metadata for audio files including ID3 tags and chapter info for podcast apps",
    input_schema={
        "type": "object",
        "properties": {
            "story_info": {
                "type": "object",
                "description": "Story assembly info from assemble_complete_story",
            },
            "repository_url": {"type": "string", "description": "Source repository URL"},
            "style": {"type": "string", "description": "Narrative style used"},
            "author": {
                "type": "string",
                "description": "Author name for metadata",
                "default": "Code Story",
            },
        },
        "required": ["story_info", "repository_url", "style"],
    },
)
async def generate_audio_metadata(args: dict) -> dict:
    """Generate metadata for audio files (ID3 tags, chapter markers, JSON sidecar)."""
    story_info = args["story_info"]
    repository_url = args["repository_url"]
    style = args["style"]
    author = args.get("author", "Code Story")

    chapters = story_info.get("chapters", [])

    # ID3 tag metadata
    id3_metadata = {
        "title": story_info.get("title", "Code Story"),
        "artist": author,
        "album": "Code Story",
        "genre": "Podcast",
        "year": str(datetime.now().year),
        "comment": f"Generated from {repository_url}",
    }

    # Chapter metadata for podcast apps (compatible with enhanced podcasts)
    chapter_metadata = [
        {
            "title": ch.get("title"),
            "start_time": ch.get("start_time_seconds", 0),
            "end_time": ch.get("start_time_seconds", 0) + ch.get("duration_seconds", 0),
            "duration_seconds": ch.get("duration_seconds", 0),
        }
        for ch in chapters
    ]

    # Full JSON metadata
    json_metadata = {
        "version": "1.0",
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "source": {
            "repository_url": repository_url,
            "style": style,
        },
        "audio": {
            "title": story_info.get("title"),
            "author": author,
            "duration_seconds": story_info.get("total_duration_seconds"),
            "duration_formatted": story_info.get("total_duration_formatted"),
            "file_size_bytes": story_info.get("file_size_bytes"),
            "format": DEFAULT_FORMAT,
            "bitrate": DEFAULT_BITRATE,
        },
        "chapters": chapter_metadata,
        "id3_tags": id3_metadata,
    }

    return {"content": [{"type": "text", "text": json.dumps(json_metadata, indent=2)}]}


@tool(
    name="save_metadata_file",
    description="Save metadata to a JSON sidecar file alongside the audio",
    input_schema={
        "type": "object",
        "properties": {
            "metadata": {"type": "object", "description": "Metadata dictionary to save"},
            "output_path": {"type": "string", "description": "Path for JSON file"},
        },
        "required": ["metadata", "output_path"],
    },
)
async def save_metadata_file(args: dict) -> dict:
    """Save metadata to a JSON file alongside the audio."""
    metadata = args["metadata"]
    output_path = args["output_path"]

    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, "w") as f:
        json.dump(metadata, f, indent=2)

    result = {
        "file_path": str(output_file),
        "file_size_bytes": output_file.stat().st_size,
        "saved_at": datetime.utcnow().isoformat() + "Z",
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}


@tool(
    name="get_assembly_stats",
    description="Get statistics about an assembled audio file",
    input_schema={
        "type": "object",
        "properties": {
            "file_path": {"type": "string", "description": "Path to audio file to analyze"},
        },
        "required": ["file_path"],
    },
)
async def get_assembly_stats(args: dict) -> dict:
    """Analyze an assembled audio file and return statistics."""
    file_path = args["file_path"]

    audio = _load_audio_file(file_path)
    file_info = Path(file_path).stat()

    result = {
        "file_path": file_path,
        "duration_ms": len(audio),
        "duration_seconds": len(audio) / 1000,
        "duration_formatted": _format_duration(len(audio)),
        "channels": audio.channels,
        "sample_width": audio.sample_width,
        "frame_rate": audio.frame_rate,
        "frame_count": audio.frame_count(),
        "dbfs": audio.dBFS if audio.dBFS != float("-inf") else None,
        "max_dbfs": audio.max_dBFS,
        "file_size_bytes": file_info.st_size,
        "bitrate_estimate_kbps": (file_info.st_size * 8) / (len(audio) / 1000) / 1000,
    }

    return {"content": [{"type": "text", "text": json.dumps(result, indent=2)}]}
```

### Task 2: Create Assembly MCP Server

**File**: `src/codestory/skills/voice/assembly_server.py`

```python
"""MCP server for audio assembly tools.

Creates in-process MCP server for Code Story audio assembly.
"""

from claude_agent_sdk import create_sdk_mcp_server

from codestory.skills.voice.assembly import (
    assemble_chapter,
    assemble_complete_story,
    generate_audio_metadata,
    save_metadata_file,
    get_assembly_stats,
)


def create_assembly_mcp_server():
    """Create MCP server with audio assembly tools.

    Tools accessible as:
    - mcp__assembly__assemble_chapter
    - mcp__assembly__assemble_complete_story
    - mcp__assembly__generate_audio_metadata
    - mcp__assembly__save_metadata_file
    - mcp__assembly__get_assembly_stats
    """
    return create_sdk_mcp_server(
        name="assembly",
        version="1.0.0",
        tools=[
            assemble_chapter,
            assemble_complete_story,
            generate_audio_metadata,
            save_metadata_file,
            get_assembly_stats,
        ],
    )
```

### Task 3: Update Voice Package Init

**File**: `src/codestory/skills/voice/__init__.py`

```python
"""Voice synthesis skills for Code Story.

Provides ElevenLabs integration, script preparation, and audio assembly.
"""

from codestory.skills.voice.synthesis import (
    synthesize_text,
    synthesize_with_style,
    get_elevenlabs_voices,
    check_elevenlabs_quota,
    create_voice_mcp_server,
)
from codestory.skills.voice.preparation import (
    process_voice_markers,
    chunk_text_for_synthesis,
    prepare_segment,
    prepare_full_script,
    validate_prepared_script,
    get_preparation_stats,
    create_preparation_mcp_server,
)
from codestory.skills.voice.assembly import (
    assemble_chapter,
    assemble_complete_story,
    generate_audio_metadata,
    save_metadata_file,
    get_assembly_stats,
)
from codestory.skills.voice.assembly_server import create_assembly_mcp_server
from codestory.skills.voice.director import (
    estimate_synthesis_cost,
    synthesize_story_segments,
    retry_failed_segments,
    generate_voice_preview,
    create_voice_director_agent,
    create_director_mcp_server,
)

__all__ = [
    # Synthesis tools
    "synthesize_text",
    "synthesize_with_style",
    "get_elevenlabs_voices",
    "check_elevenlabs_quota",
    "create_voice_mcp_server",
    # Preparation tools
    "process_voice_markers",
    "chunk_text_for_synthesis",
    "prepare_segment",
    "prepare_full_script",
    "validate_prepared_script",
    "get_preparation_stats",
    "create_preparation_mcp_server",
    # Assembly tools
    "assemble_chapter",
    "assemble_complete_story",
    "generate_audio_metadata",
    "save_metadata_file",
    "get_assembly_stats",
    "create_assembly_mcp_server",
    # Director agent
    "estimate_synthesis_cost",
    "synthesize_story_segments",
    "retry_failed_segments",
    "generate_voice_preview",
    "create_voice_director_agent",
    "create_director_mcp_server",
]
```

### Task 4: Add pydub Dependency

**File**: `pyproject.toml`

Add to `[project.dependencies]`:

```toml
"pydub>=0.25.1",
```

**Note**: ffmpeg is required as a system dependency for pydub. Document in README:

```markdown
## System Requirements

- Python 3.12+
- ffmpeg (for audio processing)

### Installing ffmpeg

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt-get install ffmpeg
```

**Windows:**
Download from https://ffmpeg.org/download.html and add to PATH.
```

### Task 5: Create Assembly Tests

**File**: `tests/skills/voice/test_assembly.py`

```python
"""Tests for audio assembly tools."""

import json
import pytest
from pathlib import Path
from unittest.mock import MagicMock, patch, AsyncMock

from codestory.skills.voice.assembly import (
    assemble_chapter,
    assemble_complete_story,
    generate_audio_metadata,
    save_metadata_file,
    get_assembly_stats,
    _format_duration,
    _create_silence,
    _normalize_audio,
)


class TestHelperFunctions:
    """Tests for helper functions."""

    def test_format_duration_seconds(self):
        """Test formatting short durations."""
        assert _format_duration(30000) == "0:30"
        assert _format_duration(90000) == "1:30"
        assert _format_duration(125000) == "2:05"

    def test_format_duration_hours(self):
        """Test formatting long durations."""
        assert _format_duration(3600000) == "1:00:00"
        assert _format_duration(3661000) == "1:01:01"
        assert _format_duration(7200000) == "2:00:00"

    def test_create_silence(self):
        """Test silence creation."""
        silence = _create_silence(1000)
        assert len(silence) == 1000
        assert silence.dBFS == float("-inf")  # Silent audio


class TestAssembleChapter:
    """Tests for assemble_chapter tool."""

    @pytest.mark.asyncio
    async def test_assemble_chapter_basic(self, tmp_path):
        """Test basic chapter assembly."""
        # Create mock segment files
        from pydub.generators import Sine

        segment1_path = tmp_path / "seg1.mp3"
        segment2_path = tmp_path / "seg2.mp3"

        # Generate test audio (1 second sine waves)
        audio1 = Sine(440).to_audio_segment(duration=1000)
        audio2 = Sine(880).to_audio_segment(duration=1000)

        audio1.export(str(segment1_path), format="mp3")
        audio2.export(str(segment2_path), format="mp3")

        output_path = tmp_path / "chapter1.mp3"

        result = await assemble_chapter({
            "segment_files": [
                {"file_path": str(segment1_path), "segment_index": 0},
                {"file_path": str(segment2_path), "segment_index": 1, "pause_before_seconds": 0.5},
            ],
            "chapter_number": 1,
            "chapter_title": "Introduction",
            "output_path": str(output_path),
        })

        response = json.loads(result["content"][0]["text"])

        assert response["chapter_number"] == 1
        assert response["title"] == "Introduction"
        assert Path(response["file_path"]).exists()
        assert response["duration_ms"] > 2000  # At least 2 seconds + pause
        assert response["segment_count"] == 2

    @pytest.mark.asyncio
    async def test_assemble_chapter_no_normalize(self, tmp_path):
        """Test chapter assembly without normalization."""
        from pydub.generators import Sine

        segment_path = tmp_path / "seg.mp3"
        Sine(440).to_audio_segment(duration=500).export(str(segment_path), format="mp3")

        output_path = tmp_path / "chapter.mp3"

        result = await assemble_chapter({
            "segment_files": [{"file_path": str(segment_path)}],
            "chapter_number": 1,
            "chapter_title": "Test",
            "output_path": str(output_path),
            "normalize": False,
        })

        response = json.loads(result["content"][0]["text"])
        assert Path(response["file_path"]).exists()


class TestAssembleCompleteStory:
    """Tests for assemble_complete_story tool."""

    @pytest.mark.asyncio
    async def test_assemble_story(self, tmp_path):
        """Test complete story assembly."""
        from pydub.generators import Sine

        # Create chapter files
        ch1_path = tmp_path / "ch1.mp3"
        ch2_path = tmp_path / "ch2.mp3"

        Sine(440).to_audio_segment(duration=2000).export(str(ch1_path), format="mp3")
        Sine(880).to_audio_segment(duration=3000).export(str(ch2_path), format="mp3")

        output_path = tmp_path / "story.mp3"

        result = await assemble_complete_story({
            "chapter_files": [
                {"file_path": str(ch1_path), "chapter_number": 1, "title": "Beginning"},
                {"file_path": str(ch2_path), "chapter_number": 2, "title": "Conclusion"},
            ],
            "story_title": "Test Story",
            "output_path": str(output_path),
        })

        response = json.loads(result["content"][0]["text"])

        assert response["title"] == "Test Story"
        assert response["chapter_count"] == 2
        assert len(response["chapters"]) == 2
        assert response["chapters"][0]["title"] == "Beginning"
        assert response["chapters"][1]["start_time_ms"] > response["chapters"][0]["start_time_ms"]


class TestGenerateMetadata:
    """Tests for generate_audio_metadata tool."""

    @pytest.mark.asyncio
    async def test_generate_metadata(self):
        """Test metadata generation."""
        story_info = {
            "title": "Understanding Flask",
            "total_duration_seconds": 180.5,
            "total_duration_formatted": "3:00",
            "file_size_bytes": 2880000,
            "chapters": [
                {"title": "Intro", "start_time_seconds": 0, "duration_seconds": 60},
                {"title": "Routing", "start_time_seconds": 62, "duration_seconds": 60},
                {"title": "Templates", "start_time_seconds": 124, "duration_seconds": 56},
            ],
        }

        result = await generate_audio_metadata({
            "story_info": story_info,
            "repository_url": "https://github.com/pallets/flask",
            "style": "tutorial",
            "author": "Code Story",
        })

        metadata = json.loads(result["content"][0]["text"])

        assert metadata["version"] == "1.0"
        assert metadata["source"]["repository_url"] == "https://github.com/pallets/flask"
        assert metadata["source"]["style"] == "tutorial"
        assert metadata["audio"]["title"] == "Understanding Flask"
        assert len(metadata["chapters"]) == 3
        assert metadata["id3_tags"]["artist"] == "Code Story"
        assert metadata["id3_tags"]["genre"] == "Podcast"


class TestSaveMetadata:
    """Tests for save_metadata_file tool."""

    @pytest.mark.asyncio
    async def test_save_metadata(self, tmp_path):
        """Test saving metadata to file."""
        metadata = {"version": "1.0", "title": "Test"}
        output_path = tmp_path / "metadata.json"

        result = await save_metadata_file({
            "metadata": metadata,
            "output_path": str(output_path),
        })

        response = json.loads(result["content"][0]["text"])

        assert Path(response["file_path"]).exists()

        with open(output_path) as f:
            saved = json.load(f)

        assert saved == metadata


class TestGetAssemblyStats:
    """Tests for get_assembly_stats tool."""

    @pytest.mark.asyncio
    async def test_get_stats(self, tmp_path):
        """Test getting audio statistics."""
        from pydub.generators import Sine

        audio_path = tmp_path / "test.mp3"
        audio = Sine(440).to_audio_segment(duration=5000)
        audio.export(str(audio_path), format="mp3")

        result = await get_assembly_stats({
            "file_path": str(audio_path),
        })

        stats = json.loads(result["content"][0]["text"])

        assert stats["duration_ms"] >= 4900  # Allow small encoding variance
        assert stats["duration_ms"] <= 5100
        assert stats["channels"] >= 1
        assert stats["frame_rate"] > 0
        assert stats["file_size_bytes"] > 0
```

## Files Created/Modified

| File | Action | Purpose |
|------|--------|---------|
| `src/codestory/skills/voice/assembly.py` | Create | Audio assembly tools with @tool decorator |
| `src/codestory/skills/voice/assembly_server.py` | Create | MCP server for assembly tools |
| `src/codestory/skills/voice/__init__.py` | Update | Export assembly tools and server |
| `pyproject.toml` | Update | Add pydub dependency |
| `tests/skills/voice/test_assembly.py` | Create | Assembly tool tests |

## Validation Criteria

1. `assemble_chapter` combines segments with transitions
2. `assemble_complete_story` tracks chapter markers
3. `generate_audio_metadata` creates podcast-compatible metadata
4. `save_metadata_file` writes JSON sidecar
5. `get_assembly_stats` analyzes audio properties
6. All tools return proper `{"content": [{"type": "text", "text": ...}]}` format
7. All tests pass

## Tool Naming

Assembly tools accessible as:
- `mcp__assembly__assemble_chapter`
- `mcp__assembly__assemble_complete_story`
- `mcp__assembly__generate_audio_metadata`
- `mcp__assembly__save_metadata_file`
- `mcp__assembly__get_assembly_stats`

## Integration Points

- **Voice Director Agent**: Uses assembly tools after synthesis complete
- **Story Architect**: Provides chapter structure for assembly
- **API Layer**: Returns assembled audio URLs and metadata

## Audio Processing Details

### Normalization
- Target: -20 dBFS for consistent loudness
- Applied per-segment before concatenation

### Transitions
- 100ms fade in/out on chapters
- 2 second silence between chapters
- 1 second intro silence
- 500ms final fade out

### Output Format
- MP3 at 192kbps (good quality/size balance)
- Chapter markers in JSON sidecar for podcast apps
- ID3 tags embedded for player compatibility

## Next Step

Phase 5 complete. Ready for 06-01-PLAN.md (FastAPI Backend).
